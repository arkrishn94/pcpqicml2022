{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2046c600-7a61-4815-b5af-6b296107f326",
   "metadata": {},
   "source": [
    "Run dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q numpy\n",
    "!pip install h5py\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4724a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "import wget\n",
    "import importlib\n",
    "import os.path\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "import scipy.sparse\n",
    "\n",
    "from index_class import ivf_index\n",
    "from index_class import cluster_index\n",
    "from index_class import data_io\n",
    "import results\n",
    "\n",
    "import test \n",
    "\n",
    "np.random.seed(101) #Fix the seed for reproducible results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d97f0e-a593-4e49-8f18-e17970c6f841",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb460667-ae33-4e49-942f-f9022fa2cc4d",
   "metadata": {},
   "source": [
    "Set `dataset` to the name of the dataset to index -- `'glove-100'` for Glove-100 and `'lastfm-64'` for Last.fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d263ebf-05d4-4122-b6bf-7897ca07fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'glove-100' #set to 'lastfm-64' for Last.fm experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58043410-b134-449f-b4ab-126d2f447ec8",
   "metadata": {},
   "source": [
    "Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37645b59-69d5-47ef-ab27-22195fce1ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "wget.download('http://ann-benchmarks.com/glove-100-angular.hdf5') #glove-100\n",
    "wget.download('http://ann-benchmarks.com/lastfm-64-dot.hdf5') #lastfm-64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f2230-bfcb-4246-89b7-4472ba593897",
   "metadata": {},
   "source": [
    "Set parameters of index for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7db0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dict = {'f'        : \"glove-100-angular.hdf5\", \n",
    "            'n_clusters' : 1024,\n",
    "            'M_PQ'       : 25,\n",
    "            'Scann_t'    : 0.2/8,\n",
    "            'n_probe'    : 128}\n",
    "\n",
    "lastfm_dict = {'f'       : \"lastfm-64-dot.hdf5\", \n",
    "            'n_clusters' : 256,\n",
    "            'M_PQ'       : 16,\n",
    "            'Scann_t'    : 0.2/8,\n",
    "            'n_probe'    : 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b46db6-3c49-40ae-8327-b99487105dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = glove_dict if dataset == 'glove-100' else lastfm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f290f3-4677-4132-9736-b40faa4fdb1c",
   "metadata": {},
   "source": [
    "Load the dataset, normalize for dor-product search and sample `num_queries` queries from test set for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf76a4-0ea7-422c-a5c7-cd608a299a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(data_dict['f'], 'r')\n",
    "#Sample desired number of data points and query points.\n",
    "n, num_queries = f['train'].shape[0], 1000\n",
    "\n",
    "X = preprocessing.normalize(f['train'][:]) #normalized for cosine similarity.\n",
    "\n",
    "iq = np.random.choice(f['test'].shape[0], size=num_queries, replace=False)\n",
    "Q = f['test'][np.sort(iq)] # Sample num_queries from the test queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ac743",
   "metadata": {},
   "source": [
    "# List and build indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce05ba",
   "metadata": {},
   "source": [
    "In this section we index `X` the dataset using each kind of method -- `k-means`, `PCPQ`, `Q-PCPQ`, `ScaNN`, `APCPQ` and `Q-APCPQ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc3ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting global variables for index parameters.\n",
    "n_clusters = data_dict['n_clusters'] #Number of clusters in initial clustering of data\n",
    "M_PQ = data_dict['M_PQ'] #m\n",
    "K_PQ16, K_PQ256 = 16, 256 #k\n",
    "SQ = 8 #Scalar quantizer, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c5c10-5fc2-4bf9-bff0-557cc68312db",
   "metadata": {},
   "source": [
    "Initial clustering of datapoints `X` into `n_clusters` partitions. The data is clustered once, saved and used for each indexing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6106620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVF Indexing loaded from file: results/IVFIndex_glove-100_1024\n"
     ]
    }
   ],
   "source": [
    "ivfix = ivf_index.IVFIndex(num_cluster_indexes=n_clusters, data_name=data_name)\n",
    "ivfix.build_ivf_index(X, save_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c7aa2-2c25-4a65-b1a8-f89b14aaf1ce",
   "metadata": {},
   "source": [
    "List of the methods of indexing is stored in `cluster_index_types`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa3cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_index_types = [\n",
    "                        (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.KMeansIndex(K_PQ16)], {}, 'k-means++'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.ProjCIndex(K_PQ16)],\n",
    "                        {'initializer':cluster_index.ProjCIndex.initialize_kmeans, 'descent':True}, 'PCPQ'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.ProjCIndex(K_PQ16)], \n",
    "                        {'initializer':cluster_index.ProjCIndex.initialize_kmeans, 'descent':True, 'SQ':SQ}, 'Q-PCPQ'),                    \n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.ScannIndex(K_PQ16, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True}, 'ScaNN'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.ScannIndex(K_PQ16, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True, 'project':True}, 'APCPQ'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ16, M_PQ, cluster_index.ScannIndex(K_PQ16, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True, 'project':True, 'SQ':SQ}, 'Q-APCPQ'),\n",
    "                       \n",
    "                        (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.KMeansIndex(K_PQ256)], {}, 'k-means++'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.ProjCIndex(K_PQ256)], \n",
    "                       {'initializer':cluster_index.ProjCIndex.initialize_kmeans, 'descent':True}, 'PCPQ'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.ProjCIndex(K_PQ256)], \n",
    "                       {'initializer':cluster_index.ProjCIndex.initialize_kmeans, 'descent':True, 'SQ':SQ}, 'Q-PCPQ'),                       \n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.ScannIndex(K_PQ256, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True}, 'ScaNN'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.ScannIndex(K_PQ256, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True, 'project':True}, 'APCPQ'),\n",
    "                       \n",
    "                       (cluster_index.PQIndex, [K_PQ256, M_PQ, cluster_index.ScannIndex(K_PQ256, T=data_dict['Scann_t'])],\n",
    "                        {'descent':True, 'project':True, 'SQ':SQ}, 'Q-APCPQ')\n",
    "                      ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13371c-2274-4449-99ea-b4696d210170",
   "metadata": {},
   "source": [
    "Each method listed in `cluster_index_types` is used to index the data. Each index is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the indexes if not already saved otherwise load\n",
    "for (ix_class, initargs, buildkwargs, label) in cluster_index_types: \n",
    "    cix = ivfix.build_cluster_indexes(ix_class, *initargs, save_index=True, **buildkwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17e9eb",
   "metadata": {},
   "source": [
    "# Recall of top 1@N.\n",
    "\n",
    "Plotting the recall for `1@N` for different values of `N`, i.e. results of Figure 4 in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ab79daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max = 30 #Max value of N desired for plot\n",
    "N_list = np.arange(1, N_max + 1, 2)\n",
    "n_probe = data_dict['n_probe'] #Number of first level partitioning probed \n",
    "\n",
    "top_k = 1\n",
    "eps_scaling = 1.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbe52b-5d15-4a2e-ba70-dcd828c6834a",
   "metadata": {},
   "source": [
    "Compute exact scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fcdfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max = max(N_list)\n",
    "exact_scores = np.zeros((Q.shape[0], N_max))\n",
    "for i in tqdm(range(Q.shape[0])): exact_scores[i] = np.sort(np.partition(X@(-Q[i]), N_max-1)[:N_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e5e65-3cfd-4957-9d50-0d73403d0b60",
   "metadata": {},
   "source": [
    "Compute average recall1@N for each method over queries `Q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_N = []\n",
    "for i in tqdm(range(0, len(cluster_index_types))):\n",
    "    r = []\n",
    "    (ix_class, initargs, buildkwargs, label) = cluster_index_types[i] \n",
    "    cix = ivfix.build_cluster_indexes(ix_class, *initargs, save_index=True, **buildkwargs)\n",
    "    for i_n in tqdm(range(len(N_list)), leave=False):\n",
    "        N_val = N_list[i_n]\n",
    "        r.append(np.mean(test.test_score_recall(X,Q,exact_scores,top_k,N_val,ivfix,eps_scaling,*[n_probe, N_val, N_val, cix])))\n",
    "    rs_N.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cbac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"%s_1@N_list\"%dataset #Label to save results\n",
    "R = results.Results(cluster_index_types, rs_N, **{'N_list':N_list, 'top_k':top_k, 'n_probe':n_probe, 'eps_scaling':eps_scaling})\n",
    "R.save_results(label)\n",
    "# R = results.Results.load_results(label) #To load results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988a14c-a90d-4cb6-a91f-da425df05c91",
   "metadata": {},
   "source": [
    "Plot figures from Figure 4 in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_split = [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(10, 8)\n",
    "for i in range(len(index_split)):\n",
    "    for i_n in index_split[i]: \n",
    "        axs[i//2][i%2].plot(R.kwargs['N_list'], R.results[i_n], label=R.index_types[i_n][3])\n",
    "    axs[i//2][i%2].set_xlabel('N')\n",
    "    axs[i//2][i%2].legend()\n",
    "    axs[i//2][i%2].set_title('Recall1@N for %s, (%d - bit)' % (dataset, K_PQ/8))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
